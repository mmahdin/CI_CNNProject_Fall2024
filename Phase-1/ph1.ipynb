{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ph1 import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from eecs598.utils import reset_seed\n",
    "from collections import OrderedDict\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "to_float= torch.float\n",
    "to_long = torch.long\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "loader_train, loader_val, loader_test = load_CIFAR(path='./datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n",
    "  \"\"\"\n",
    "  Multiply lrd to the learning rate if epoch is in schedule\n",
    "  \n",
    "  Inputs:\n",
    "  - optimizer: An Optimizer object we will use to train the model\n",
    "  - lrd: learning rate decay; a factor multiplied at scheduled epochs\n",
    "  - epochs: the current epoch number\n",
    "  - schedule: the list of epochs that requires learning rate update\n",
    "  \n",
    "  Returns: Nothing, but learning rate might be updated\n",
    "  \"\"\"\n",
    "  if epoch in schedule:\n",
    "    for param_group in optimizer.param_groups:\n",
    "      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n",
    "      param_group['lr'] *= lrd\n",
    "\n",
    "\n",
    "def check_accuracy_part34(loader, model):\n",
    "  if loader.dataset.train:\n",
    "    print('Checking accuracy on validation set')\n",
    "  else:\n",
    "    print('Checking accuracy on test set')   \n",
    "  num_correct = 0\n",
    "  num_samples = 0\n",
    "  model.eval()  # set model to evaluation mode\n",
    "  with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "      x = x.to(device=device, dtype=to_float)  # move to device, e.g. GPU\n",
    "      y = y.to(device=device, dtype=to_long)\n",
    "      scores = model(x)\n",
    "      _, preds = scores.max(1)\n",
    "      num_correct += (preds == y).sum()\n",
    "      num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "  return acc\n",
    "\n",
    "\n",
    "def train_part345(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], verbose=True):\n",
    "  \"\"\"\n",
    "  Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "  \n",
    "  Inputs:\n",
    "  - model: A PyTorch Module giving the model to train.\n",
    "  - optimizer: An Optimizer object we will use to train the model\n",
    "  - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "  \n",
    "  Returns: Nothing, but prints model accuracies during training.\n",
    "  \"\"\"\n",
    "  model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "  num_iters = epochs * len(loader_train)\n",
    "  print_every = 100\n",
    "  if verbose:\n",
    "    num_prints = num_iters // print_every + 1\n",
    "  else:\n",
    "    num_prints = epochs\n",
    "  acc_history = torch.zeros(num_prints, dtype=to_float)\n",
    "  iter_history = torch.zeros(num_prints, dtype=to_long)\n",
    "  for e in range(epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n",
    "    \n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "      model.train()  # put model to training mode\n",
    "      x = x.to(device=device, dtype=to_float)  # move to device, e.g. GPU\n",
    "      y = y.to(device=device, dtype=to_long)\n",
    "\n",
    "      scores = model(x)\n",
    "      loss = F.cross_entropy(scores, y)\n",
    "\n",
    "      # Zero out all of the gradients for the variables which the optimizer\n",
    "      # will update.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # This is the backwards pass: compute the gradient of the loss with\n",
    "      # respect to each  parameter of the model.\n",
    "      loss.backward()\n",
    "\n",
    "      # Actually update the parameters of the model using the gradients\n",
    "      # computed by the backwards pass.\n",
    "      optimizer.step()\n",
    "\n",
    "      tt = t + e * len(loader_train)\n",
    "\n",
    "      if verbose and (tt % print_every == 0 or (e == epochs-1 and t == len(loader_train)-1)):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
    "        acc = check_accuracy_part34(loader_val, model)\n",
    "        acc_history[tt // print_every] = acc\n",
    "        iter_history[tt // print_every] = tt\n",
    "        print()\n",
    "      elif not verbose and (t == len(loader_train)-1):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
    "        acc = check_accuracy_part34(loader_val, model)\n",
    "        acc_history[e] = acc\n",
    "        iter_history[e] = tt\n",
    "        print()\n",
    "  return acc_history, iter_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of specifications\n",
    "# networks = {\n",
    "#   'plain32': {\n",
    "#     'block': PlainBlock,\n",
    "#     'stage_args': [\n",
    "#       (8, 8, 5, False),\n",
    "#       (8, 16, 5, True),\n",
    "#       (16, 32, 5, True),\n",
    "#     ]\n",
    "#   },\n",
    "#   'resnet32': {\n",
    "#     'block': ResidualBlock,\n",
    "#     'stage_args': [\n",
    "#       (8, 8, 5, False),\n",
    "#       (8, 16, 5, True),\n",
    "#       (16, 32, 5, True),\n",
    "#     ]\n",
    "#   },\n",
    "# }\n",
    "networks = {\n",
    "  'resnet20': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "      (16, 16, 3, False),  # (in_channels, out_channels, num_blocks, downsample)\n",
    "      (16, 32, 3, True),\n",
    "      (32, 64, 3, True),\n",
    "    ]\n",
    "  },\n",
    "  'resnet32': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "      (16, 16, 5, False),  # Use 5 residual blocks in this stage\n",
    "      (16, 32, 5, True),\n",
    "      (32, 64, 5, True),\n",
    "    ]\n",
    "  },\n",
    "  'resnet44': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "      (16, 16, 7, False),  # Use 7 residual blocks in this stage\n",
    "      (16, 32, 7, True),\n",
    "      (32, 64, 7, True),\n",
    "    ]\n",
    "  },\n",
    "  'resnet56': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "        (16, 16, 9, False),  # Use 9 residual blocks in this stage\n",
    "        (16, 32, 9, True),\n",
    "        (32, 64, 9, True),\n",
    "    ]\n",
    "  },\n",
    "  'resnet110': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "        (16, 16, 18, False),  # Use 18 residual blocks in this stage\n",
    "        (16, 32, 18, True),\n",
    "        (32, 64, 18, True),\n",
    "    ]\n",
    "  },\n",
    "  'wideresnet': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "        (16, 32, 3, False),  # Double the channels\n",
    "        (32, 64, 3, True),\n",
    "        (64, 128, 3, True),\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "def get_resnet(name):\n",
    "  # YOUR_TURN: Impelement ResNet.__init__ and ResNet.forward\n",
    "  return ResNet(**networks[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet56 \n",
      "\n",
      "Epoch 0, Iteration 765, loss = 1.0302\n",
      "Checking accuracy on validation set\n",
      "Got 572 / 1000 correct (57.20)\n",
      "\n",
      "Epoch 1, Iteration 1531, loss = 0.8999\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "\n",
      "Epoch 2, Iteration 2297, loss = 0.6808\n",
      "Checking accuracy on validation set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "\n",
      "Epoch 3, Iteration 3063, loss = 0.6683\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "\n",
      "Epoch 4, Iteration 3829, loss = 0.4698\n",
      "Checking accuracy on validation set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "\n",
      "Epoch 5, Iteration 4595, loss = 0.3208\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "\n",
      "lr decay from 0.01 to 0.001\n",
      "Epoch 6, Iteration 5361, loss = 0.2289\n",
      "Checking accuracy on validation set\n",
      "Got 858 / 1000 correct (85.80)\n",
      "\n",
      "Epoch 7, Iteration 6127, loss = 0.2627\n",
      "Checking accuracy on validation set\n",
      "Got 861 / 1000 correct (86.10)\n",
      "\n",
      "lr decay from 0.001 to 0.0001\n",
      "Epoch 8, Iteration 6893, loss = 0.0853\n",
      "Checking accuracy on validation set\n",
      "Got 861 / 1000 correct (86.10)\n",
      "\n",
      "Epoch 9, Iteration 7659, loss = 0.1232\n",
      "Checking accuracy on validation set\n",
      "Got 860 / 1000 correct (86.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['resnet56']\n",
    "acc_history_dict = {}\n",
    "iter_history_dict = {}\n",
    "for name in names:\n",
    "  reset_seed(0)\n",
    "  print(name, '\\n')\n",
    "  model = get_resnet(name)\n",
    "  \n",
    "  optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=1e-4)\n",
    "\n",
    "  acc_history, iter_history = train_part345(model, optimizer, epochs=10, schedule=[6, 8], verbose=False)\n",
    "  acc_history_dict[name] = acc_history\n",
    "  iter_history_dict[name] = iter_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
