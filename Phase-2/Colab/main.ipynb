{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU11RABQPZeS",
        "outputId": "7d2dc203-2944-4f80-b649-3b0e8752f379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/breast-histopathology-images?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.10G/3.10G [00:37<00:00, 89.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from os import listdir\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "base_path = path+'/'+\"IDC_regular_ps50_idx5/\"\n",
        "folder = listdir(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6mPbg9GPZeS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/phase2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from drive.MyDrive.phase2.utils.utils import *\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "lr = 0.001\n",
        "weight_decay = 1e-4\n",
        "\n",
        "\n",
        "# base_paht: path to main dataset\n",
        "# base_dir: sharedd phase2 dirctory\n",
        "train_dataloader, dev_dataloader, test_dataloader = get_train_data(folder, base_path, batch_size, base_dir)"
      ],
      "metadata": {
        "id": "W54qR7n66EZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the target directory\n",
        "target_directory = '/content/drive/MyDrive/phase2/dataset/agmented'\n",
        "\n",
        "# Count the number of files in the directory\n",
        "file_count = sum(len(files) for _, _, files in os.walk(target_directory))\n",
        "\n",
        "print(f\"Total number of files in '{target_directory}': {file_count}\")"
      ],
      "metadata": {
        "id": "7E0aC6xzFN2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js793cwKPZeT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the ResNet structure for your task\n",
        "networks = {\n",
        "    'resnet18_light': {\n",
        "        'block': ResidualBlock,\n",
        "        'stage_args': [\n",
        "            (32, 64, 2, False)\n",
        "        ],\n",
        "        'dropout': True,  # Enable dropout\n",
        "        'p': 0.5  # Dropout probability\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_resnet(name):\n",
        "    return ResNet(**networks[name])\n",
        "\n",
        "\n",
        "to_float= torch.float\n",
        "to_long = torch.long\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Model and file paths\n",
        "name = 'resnet18_light'\n",
        "version = 10\n",
        "checkpoint_path = f'{base_dir}/checkpoint/{name}_{version}_checkpoint.pth'\n",
        "model_path = f'{base_dir}/models/{name}_{version}_checkpoint.pth'\n",
        "history_path = f'{base_dir}/history/{name}_{version}.pth'\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    # Resume training from checkpoint\n",
        "    print(f\"Resuming training from checkpoint: {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = get_resnet(name).to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
        "    if checkpoint['scheduler_state'] is not None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
        "\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_val_acc = checkpoint['best_val_acc']\n",
        "    train_metrics_history = checkpoint['train_history']\n",
        "    val_metrics_history = checkpoint['val_history']\n",
        "    lr_history = checkpoint['lr_history']\n",
        "\n",
        "    print(f\"Training will resume from epoch {start_epoch}.\\n\")\n",
        "\n",
        "else:\n",
        "    # Start new training\n",
        "    print(f\"Training new model: {name}\\n\")\n",
        "\n",
        "    # Initialize model and optimizer\n",
        "    model = get_resnet(name).to(device)\n",
        "    model.apply(initialize_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Define scheduler\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    # Initialize metrics and state\n",
        "    start_epoch = 0\n",
        "    best_val_acc = 0.0\n",
        "    train_metrics_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "    val_metrics_history = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "    lr_history = []\n",
        "\n",
        "# Train model\n",
        "train_metrics_history, val_metrics_history, lr_history = train_model(\n",
        "    model, optimizer, train_dataloader, dev_dataloader,\n",
        "    device=device, dtype=torch.float32, epochs=epochs,\n",
        "    scheduler=scheduler, schedule=[20, 40], verbose=True,\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    history_path=history_path\n",
        ")\n",
        "\n",
        "# Save final model and history after training completes\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Final model saved at: {model_path}\")\n",
        "\n",
        "with open(history_path, 'wb') as f:\n",
        "    pickle.dump((train_metrics_history, val_metrics_history, lr_history), f)\n",
        "print(f\"Training history saved at: {history_path}\")\n",
        "\n",
        "# Evaluate model on the test set\n",
        "test_accuracy, test_precision, test_recall, test_f1 = calculate_metrics(test_dataloader, model, device=device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, \"\n",
        "      f\"Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "# Plot metrics\n",
        "plot_all_metrics(train_metrics_history, val_metrics_history)\n",
        "plot_learning_rate(lr_history)\n",
        "plot_loss(train_metrics_history['loss'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}